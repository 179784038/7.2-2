{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision.models import resnet18\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nfrom torch.utils.tensorboard import SummaryWriter","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 定义数据增强方法：CutMix\ndef cutmix_data(images, labels, alpha):\n    # 随机选择一个样本\n    indices = torch.randperm(images.size(0))\n    shuffled_images = images[indices]\n    shuffled_labels = labels[indices]\n\n    # 计算剪切区域的大小\n    lam = np.random.beta(alpha, alpha)\n    cut_w = int(images.size(2) * np.sqrt(1 - lam))\n    cut_h = int(images.size(3) * np.sqrt(1 - lam))\n\n    # 随机选择剪切区域的位置\n    cx = np.random.randint(images.size(2))\n    cy = np.random.randint(images.size(3))\n    x1 = np.clip(cx - cut_w // 2, 0, images.size(2))\n    x2 = np.clip(cx + cut_w // 2, 0, images.size(2))\n    y1 = np.clip(cy - cut_h // 2, 0, images.size(3))\n    y2 = np.clip(cy + cut_h // 2, 0, images.size(3))\n\n    # 剪切区域替换为随机样本的剪切区域\n    images[:, :, x1:x2, y1:y2] = shuffled_images[:, :, x1:x2, y1:y2]\n\n    # 计算新的标签\n    lam = 1 - ((x2 - x1) * (y2 - y1) / (images.size(2) * images.size(3)))\n    labels = (1 - lam) * labels + lam * shuffled_labels\n\n    return images, labels","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 定义数据增强方法：Cutout\ndef cutout_data(images, labels, n_holes, length):\n    h = images.size(2)\n    w = images.size(3)\n\n    for _ in range(n_holes):\n        y = np.random.randint(h)\n        x = np.random.randint(w)\n\n        y1 = np.clip(y - length // 2, 0, h)\n        y2 = np.clip(y + length // 2, 0, h)\n        x1 = np.clip(x - length // 2, 0, w)\n        x2 = np.clip(x + length // 2, 0, w)\n\n        images[:, :, y1:y2, x1:x2] = 0\n\n    return images, labels","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mixup_data(images, labels, alpha):\n    # 随机选择另一个样本\n    indices = torch.randperm(images.size(0))\n    shuffled_images = images[indices]\n    shuffled_labels = labels[indices]\n\n    # 计算混合比例\n    lam = np.random.beta(alpha, alpha)\n    lam = max(lam, 1 - lam)\n\n    # 执行mixup\n    images = lam * images + (1 - lam) * shuffled_images\n    labels = lam * labels + (1 - lam) * shuffled_labels\n\n    return images, labels","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 设置随机种子以便结果可重现\ntorch.manual_seed(42)\nnp.random.seed(42)\n# 设置训练和测试的批处理大小\nbatch_size = 64\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 加载CIFAR-100数据集\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\ntrainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n                                        download=True, transform=transform_train)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                          shuffle=True, num_workers=4)\n\ntestset = torchvision.datasets.CIFAR100(root='./data', train=False,\n                                       download=True, transform=transform_test)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n                                         shuffle=False, num_workers=4)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 定义ResNet-18模型\nmodel = resnet18(pretrained=False, num_classes=100)\n# 定义损失函数和优化器\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.tensorboard import SummaryWriter\nimport matplotlib.pyplot as plt\n\n# 创建 SummaryWriter 对象\nwriter = SummaryWriter()\n# 训练模型\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nnum_epochs = 100\n\ntrain_losses = []\ntrain_accuracies = []\ntest_losses = []\ntest_accuracies = []\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        inputs, targets = inputs.to(device), targets.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n        # 写入训练 loss 值到 Tensorboard\n        writer.add_scalar('Train/Loss', train_loss/(batch_idx+1), epoch)\n        # 写入训练准确率到 Tensorboard\n        train_accuracy = 100. * correct / total\n        writer.add_scalar('Train/Accuracy', train_accuracy, epoch)\n        if (batch_idx + 1) % 100 == 0:\n            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n                  .format(epoch+1, num_epochs, batch_idx+1, len(trainloader),\n                          train_loss/(batch_idx+1), 100. * correct / total))\n    \n    # 在每个epoch结束后记录训练和测试的损失和准确率\n    train_loss /= len(trainloader)\n    train_accuracy = 100. * correct / total\n    train_losses.append(train_loss)\n    train_accuracies.append(train_accuracy)\n    \n    # 保存模型\ntorch.save(model, './baseline_ResNet-18')\n\n# 测试模型\nmodel.eval()\ntest_loss = 0\ntest_correct = 0\ntest_total = 0\n\nwith torch.no_grad():\n    for inputs, targets in testloader:\n        inputs, targets = inputs.to(device), targets.to(device)\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        test_loss += loss.item()\n        _, predicted = outputs.max(1)\n        test_total += targets.size(0)\n        test_correct += predicted.eq(targets).sum().item()\n\n    # 在每个epoch结束后记录测试的损失和准确率\n    test_loss /= len(testloader)\n    test_accuracy = 100. * test_correct / test_total\n    test_losses.append(test_loss)\n    test_accuracies.append(test_accuracy)\n\n# 绘制训练和测试损失变化图\nplt.figure()\nplt.plot(train_losses, label='Train Loss')\nplt.plot(test_losses, label='Test Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Test Loss')\nplt.legend()\nplt.show()\n\n# 绘制训练和测试准确率变化图\nplt.figure()\nplt.plot(train_accuracies, label='Train Accuracy')\nplt.plot(test_accuracies, label='Test Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Training and Test Accuracy')\nplt.legend()\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision.datasets import CIFAR100\nfrom torchvision.transforms import ToTensor, Normalize, RandomCrop, RandomHorizontalFlip\nfrom torch.utils.data import DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\nfrom tqdm import tqdm\n\n# 设置随机种子\ntorch.manual_seed(42)\n\n# 定义超参数\nbatch_size = 64\nlearning_rate = 0.1\nnum_epochs = 100\n\n# 定义设备\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# 加载CIFAR-100数据集并进行预处理\ntransform_train = transforms.Compose([\n    RandomCrop(32, padding=4),\n    RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\ntrain_dataset = CIFAR100(root='./data', train=True, transform=transform_train, download=True)\ntest_dataset = CIFAR100(root='./data', train=False, transform=transform_test)\n\n# 创建数据加载器\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\nimport math\n\n# 定义超参数\npatch_size = 16\n\n# 定义Vision Transformer模型\nclass VisionTransformer(nn.Module):\n    def __init__(self, d_model=512, nhead=8, num_layers=1, num_classes=100):\n        super(VisionTransformer, self).__init__()\n\n        self.patch_size = patch_size\n        self.d_model = d_model\n        self.nhead = nhead\n        self.num_layers = num_layers\n\n        self.patch_embedding = nn.Linear(patch_size * patch_size * 3, d_model)\n        self.positional_embedding = nn.Parameter(torch.randn(1, 32 * 32 // patch_size // patch_size + 1, d_model))\n        self.cls_token = nn.Parameter(torch.randn(1, 1, d_model))\n        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead)\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n        self.fc = nn.Linear(d_model, num_classes)\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        x = x.view(batch_size, 3, 32 // self.patch_size, self.patch_size, 32 // self.patch_size, self.patch_size)\n        x = x.permute(0, 2, 4, 3, 5, 1).contiguous()\n        x = x.view(batch_size, -1, self.patch_size * self.patch_size * 3)\n        x = self.patch_embedding(x)\n        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n        x = torch.cat((cls_tokens, x), dim=1)\n        x += self.positional_embedding\n        x = x.permute(1, 0, 2)\n        x = self.transformer(x)\n        x = x.mean(dim=0)\n        x = self.fc(x)\n        return x\n\n# 创建模型实例\nmodel = VisionTransformer(d_model=512, nhead=8, num_layers=3, num_classes=100)\nmodel = model.to(device)\n\n# 定义损失函数和优化器\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n\n# 记录训练过程的指标\ntrain_loss_history = []\ntest_loss_history = []\ntrain_acc_history = []\ntest_acc_history = []\n\n# 使用TensorBoard可视化训练过程\nwriter = SummaryWriter(log_dir='./logs')\n\n# 训练模型\ntotal_step = len(train_loader)\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0.0\n    correct = 0\n    total = 0\n\n    for images, labels in tqdm(train_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n\n    avg_train_loss = train_loss / len(train_loader)\n    avg_train_acc = 100.0 * correct / total\n\n    train_loss_history.append(avg_train_loss)\n    train_acc_history.append(avg_train_acc)\n\n    writer.add_scalar('Train Loss', avg_train_loss, epoch + 1)\n    writer.add_scalar('Train Accuracy', avg_train_acc, epoch + 1)\n\n    print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train Accuracy: {avg_train_acc:.2f}%')\n\n    model.eval()\n    test_loss = 0.0\n    test_correct = 0\n    test_total = 0\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            test_loss += loss.item()\n\n            _, predicted = outputs.max(1)\n            test_total += labels.size(0)\n            test_correct += predicted.eq(labels).sum().item()\n\n    avg_test_loss = test_loss / len(test_loader)\n    avg_test_acc = 100.0 * test_correct / test_total\n\n    test_loss_history.append(avg_test_loss)\n    test_acc_history.append(avg_test_acc)\n\n    writer.add_scalar('Test Loss', avg_test_loss, epoch + 1)\n    writer.add_scalar('Test Accuracy', avg_test_acc, epoch + 1)\n\n    print(f'Epoch [{epoch + 1}/{num_epochs}], Test Loss: {avg_test_loss:.4f}, Test Accuracy: {avg_test_acc:.2f}%')\n\n    scheduler.step()\n\n# 保存模型\ntorch.save(model.state_dict(), 'transformer_cifar100.pth')\n\n# 关闭TensorBoard写入器\nwriter.close()\n\n# 可视化训练过程\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.plot(train_loss_history, label='Train Loss')\nplt.plot(test_loss_history, label='Test Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(train_acc_history, label='Train Accuracy')\nplt.plot(test_acc_history, label='Test Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 可视化样本图像\ndef imshow(img):\n    img = img / 2 + 0.5     # 反归一化\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.axis('off')\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # 获取样本数据\n# 加载三张训练样本\nsample_loader = torch.utils.data.DataLoader(trainset, batch_size=3, shuffle=True, num_workers=2)\nexample_data, example_targets = next(iter(sample_loader))\n# example_data = example_data.to(device)\n# # 获取样本和标签\n# samples, labels = next(iter(sample_loader))\n# # samples = samples.to(device)\n# examples = enumerate(trainloader)\n# batch_idx, (example_data, example_targets) = next(examples)\n\n# 将样本数据进行cutmix处理\ncutmix_images, cutmix_labels = cutmix_data(example_data.clone(), example_targets.clone(), alpha=1.0)\n\n# 将样本数据进行cutout处理\ncutout_images, cutout_labels = cutout_data(example_data.clone(), example_targets.clone(), n_holes=1, length=16)\n\n# 将样本数据进行mixup处理\nmixup_images, mixup_labels = mixup_data(example_data.clone(), example_targets.clone(), alpha=1.0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Original Images:\")\nimshow(torchvision.utils.make_grid(example_data))\nprint(\"CutMix Images:\")\nimshow(torchvision.utils.make_grid(cutmix_images))\nprint(\"Cutout Images:\")\nimshow(torchvision.utils.make_grid(cutout_images))\nprint(\"Mixup Images:\")\nimshow(torchvision.utils.make_grid(mixup_images))","metadata":{},"execution_count":null,"outputs":[]}]}